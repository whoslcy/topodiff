{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import create_models\n",
    "from topodiff.resample import UniformSampler\n",
    "from topodiff.image_datasets_diffusion_model import load_data\n",
    "from topodiff.fp16_util import MixedPrecisionTrainer\n",
    "import torch\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNetModel(\n",
      "  (time_embed): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "    (1): SiLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (input_blocks): ModuleList(\n",
      "    (0): TimestepEmbedSequential(\n",
      "      (0): Conv2d(6, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1-3): 3 x TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0.3, inplace=False)\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Identity()\n",
      "      )\n",
      "    )\n",
      "    (4): TimestepEmbedSequential(\n",
      "      (0): Downsample(\n",
      "        (op): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (5): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0.3, inplace=False)\n",
      "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (6-7): 2 x TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0.3, inplace=False)\n",
      "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Identity()\n",
      "      )\n",
      "    )\n",
      "    (8): TimestepEmbedSequential(\n",
      "      (0): Downsample(\n",
      "        (op): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (9): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=512, out_features=768, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0.3, inplace=False)\n",
      "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): AttentionBlock(\n",
      "        (norm): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
      "        (qkv): Conv1d(384, 1152, kernel_size=(1,), stride=(1,))\n",
      "        (attention): QKVAttentionLegacy()\n",
      "        (proj_out): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (10-11): 2 x TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=512, out_features=768, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0.3, inplace=False)\n",
      "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Identity()\n",
      "      )\n",
      "      (1): AttentionBlock(\n",
      "        (norm): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
      "        (qkv): Conv1d(384, 1152, kernel_size=(1,), stride=(1,))\n",
      "        (attention): QKVAttentionLegacy()\n",
      "        (proj_out): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (12): TimestepEmbedSequential(\n",
      "      (0): Downsample(\n",
      "        (op): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (13): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0.3, inplace=False)\n",
      "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): AttentionBlock(\n",
      "        (norm): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
      "        (qkv): Conv1d(512, 1536, kernel_size=(1,), stride=(1,))\n",
      "        (attention): QKVAttentionLegacy()\n",
      "        (proj_out): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (14-15): 2 x TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0.3, inplace=False)\n",
      "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Identity()\n",
      "      )\n",
      "      (1): AttentionBlock(\n",
      "        (norm): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
      "        (qkv): Conv1d(512, 1536, kernel_size=(1,), stride=(1,))\n",
      "        (attention): QKVAttentionLegacy()\n",
      "        (proj_out): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (middle_block): TimestepEmbedSequential(\n",
      "    (0): ResBlock(\n",
      "      (in_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (h_upd): Identity()\n",
      "      (x_upd): Identity()\n",
      "      (emb_layers): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "      )\n",
      "      (out_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Dropout(p=0.3, inplace=False)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (skip_connection): Identity()\n",
      "    )\n",
      "    (1): AttentionBlock(\n",
      "      (norm): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
      "      (qkv): Conv1d(512, 1536, kernel_size=(1,), stride=(1,))\n",
      "      (attention): QKVAttentionLegacy()\n",
      "      (proj_out): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "    (2): ResBlock(\n",
      "      (in_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (h_upd): Identity()\n",
      "      (x_upd): Identity()\n",
      "      (emb_layers): Sequential(\n",
      "        (0): SiLU()\n",
      "        (1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "      )\n",
      "      (out_layers): Sequential(\n",
      "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
      "        (1): SiLU()\n",
      "        (2): Dropout(p=0.3, inplace=False)\n",
      "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "      (skip_connection): Identity()\n",
      "    )\n",
      "  )\n",
      "  (output_blocks): ModuleList(\n",
      "    (0-2): 3 x TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 1024, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0.3, inplace=False)\n",
      "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): AttentionBlock(\n",
      "        (norm): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
      "        (qkv): Conv1d(512, 1536, kernel_size=(1,), stride=(1,))\n",
      "        (attention): QKVAttentionLegacy()\n",
      "        (proj_out): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (3): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 896, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(896, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0.3, inplace=False)\n",
      "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(896, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): AttentionBlock(\n",
      "        (norm): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
      "        (qkv): Conv1d(512, 1536, kernel_size=(1,), stride=(1,))\n",
      "        (attention): QKVAttentionLegacy()\n",
      "        (proj_out): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "      (2): Upsample(\n",
      "        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (4): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 896, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(896, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=512, out_features=768, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0.3, inplace=False)\n",
      "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(896, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): AttentionBlock(\n",
      "        (norm): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
      "        (qkv): Conv1d(384, 1152, kernel_size=(1,), stride=(1,))\n",
      "        (attention): QKVAttentionLegacy()\n",
      "        (proj_out): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (5-6): 2 x TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 768, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=512, out_features=768, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0.3, inplace=False)\n",
      "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): AttentionBlock(\n",
      "        (norm): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
      "        (qkv): Conv1d(384, 1152, kernel_size=(1,), stride=(1,))\n",
      "        (attention): QKVAttentionLegacy()\n",
      "        (proj_out): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "    )\n",
      "    (7): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(640, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=512, out_features=768, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0.3, inplace=False)\n",
      "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(640, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): AttentionBlock(\n",
      "        (norm): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
      "        (qkv): Conv1d(384, 1152, kernel_size=(1,), stride=(1,))\n",
      "        (attention): QKVAttentionLegacy()\n",
      "        (proj_out): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
      "      )\n",
      "      (2): Upsample(\n",
      "        (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (8): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 640, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(640, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0.3, inplace=False)\n",
      "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(640, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (9-10): 2 x TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0.3, inplace=False)\n",
      "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (11): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0.3, inplace=False)\n",
      "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): Upsample(\n",
      "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (12): TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0.3, inplace=False)\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (13-15): 3 x TimestepEmbedSequential(\n",
      "      (0): ResBlock(\n",
      "        (in_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (h_upd): Identity()\n",
      "        (x_upd): Identity()\n",
      "        (emb_layers): Sequential(\n",
      "          (0): SiLU()\n",
      "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
      "        )\n",
      "        (out_layers): Sequential(\n",
      "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
      "          (1): SiLU()\n",
      "          (2): Dropout(p=0.3, inplace=False)\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "        (skip_connection): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (out): Sequential(\n",
      "    (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
      "    (1): SiLU()\n",
      "    (2): Conv2d(128, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "image_size = 64\n",
    "mean_variance_use_fp16 = True\n",
    "\n",
    "mean_variance = create_models.mean_variance()\n",
    "print(mean_variance)\n",
    "\n",
    "diffusion = create_models.gaussian_diffusion(\n",
    "    steps=1000,\n",
    "    learn_sigma=True,\n",
    "    sigma_small=False,\n",
    "    noise_schedule=\"cosine\",\n",
    "    use_kl=False,\n",
    "    predict_xstart=False,\n",
    "    rescale_timesteps=False,\n",
    "    rescale_learned_sigmas=False,\n",
    "    timestep_respacing=\"\",\n",
    ")\n",
    "schedule_sampler = UniformSampler(diffusion)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "mean_variance = mean_variance.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "data = load_data(\n",
    "  data_dir=r\".\\data\\dataset_1_diff\\training_data\",\n",
    "  batch_size=batch_size,\n",
    "  image_size=image_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "trainer = MixedPrecisionTrainer(mean_variance, mean_variance_use_fp16)\n",
    "optimizer = torch.optim.AdamW(mean_variance.parameters(), lr=1e-4)\n",
    "ema_rate = 0.9999\n",
    "ema_parameters = copy.deepcopy(trainer.master_params)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    images: torch.Tensor\n",
    "    constraints: torch.Tensor\n",
    "    for images, constraints, _ in data:\n",
    "        images = images.to(device)\n",
    "        constraints = constraints.to(device)\n",
    "        time_steps, weights = schedule_sampler.sample(batch_size, device)\n",
    "        loss = (diffusion.training_losses(mean_variance, images, constraints, time_steps)[\"loss\"] * weights).mean()\n",
    "        \n",
    "        trainer.zero_grad()\n",
    "        trainer.backward(loss)\n",
    "        if trainer.optimize(optimizer):\n",
    "            target: torch.Tensor\n",
    "            source: torch.Tensor\n",
    "            for target, source in zip(ema_parameters, trainer.master_params):\n",
    "                target.detach().mul_(ema_rate).add_(source, alpha=1 - ema_rate)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topodiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
