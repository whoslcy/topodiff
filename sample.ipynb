{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import create_models\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "\n",
    "mean_variance = create_models.mean_variance()\n",
    "diffusion = create_models.spaced_diffusion()\n",
    "regressor = create_models.regressor()\n",
    "classifier = create_models.classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderUNetModel(\n",
       "  (time_embed): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (input_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1-2): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (x_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(256, 768, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(256, 768, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (x_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(384, 1152, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(384, 1152, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (x_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (10): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(512, 1536, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (11): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(512, 1536, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block): TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (1): AttentionBlock(\n",
       "      (norm): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "      (qkv): Conv1d(512, 1536, kernel_size=(1,), stride=(1,))\n",
       "      (attention): QKVAttentionLegacy()\n",
       "      (proj_out): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "    (1): SiLU()\n",
       "    (2): AttentionPool2d(\n",
       "      (qkv_proj): Conv1d(512, 1536, kernel_size=(1,), stride=(1,))\n",
       "      (c_proj): Conv1d(512, 2, kernel_size=(1,), stride=(1,))\n",
       "      (attention): QKVAttention()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoints_path = Path(r\".\\checkpoints\")\n",
    "cpu = torch.cpu.current_device()\n",
    "gpu = torch.cuda.current_device()\n",
    "def get_state_dict(path: Path):\n",
    "    return torch.load(path, map_location=cpu, weights_only=True)\n",
    "\n",
    "mean_variance_path = checkpoints_path / \"diff_checkpoint\" / \"model_180000.pt\"\n",
    "mean_variance.load_state_dict(get_state_dict(mean_variance_path))\n",
    "mean_variance.to(gpu)\n",
    "mean_variance.convert_to_fp16()\n",
    "mean_variance.eval()\n",
    "\n",
    "regressor_path = checkpoints_path / \"reg_checkpoint\" / \"model_350000.pt\"\n",
    "regressor.load_state_dict(get_state_dict(regressor_path))\n",
    "regressor.to(gpu)\n",
    "regressor.eval()\n",
    "\n",
    "classifier_path = checkpoints_path / \"class_checkpoint\" / \"model_299999.pt\"\n",
    "classifier.load_state_dict(get_state_dict(classifier_path))\n",
    "classifier.to(gpu)\n",
    "classifier.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "channel_count = 1\n",
    "shape = (batch_size, channel_count, image_size, image_size)\n",
    "\n",
    "def cond_fn_1(x: torch.Tensor, time_steps: torch.Tensor):\n",
    "    with torch.enable_grad():\n",
    "        x_in = x.detach().requires_grad_()\n",
    "        logits = regressor(x_in, time_steps)\n",
    "        grad = torch.autograd.grad(logits.sum(), x_in)[0]\n",
    "        return (-1) * grad[:,0,:,:].reshape(shape) * 4.0\n",
    "\n",
    "def cond_fn_2(x: torch.Tensor, time_steps: torch.Tensor):\n",
    "    with torch.enable_grad():\n",
    "        x_in = x.detach().requires_grad_()\n",
    "        logits: torch.Tensor = classifier(x_in, time_steps)\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        selected = log_probs[range(len(logits)), 1]\n",
    "        grad = torch.autograd.grad(selected.sum(), x_in)[0]\n",
    "        return grad[:,0,:,:].reshape(shape) * 3.0\n",
    "\n",
    "\n",
    "def get_boundary_condition(condition_name: str):\n",
    "    folder = Path(r\".\\data\\dataset_1_diff\\test_data_level_1\")\n",
    "    path = folder / f\"cons_{condition_name}_array_200.npy\"\n",
    "    ndarray = np.transpose(np.load(path), [2, 0, 1]).astype(np.float32)\n",
    "    tensor = torch.unsqueeze(torch.as_tensor(ndarray), 0) # Add batch size dimension\n",
    "    return tensor.to(gpu)\n",
    "\n",
    "sample = diffusion.p_sample_loop(\n",
    "    model=mean_variance,\n",
    "    shape=shape,\n",
    "    cons=get_boundary_condition(\"pf\"),\n",
    "    loads=get_boundary_condition(\"load\"),\n",
    "    BCs=get_boundary_condition(\"bc\"),\n",
    "    noise=None,\n",
    "    clip_denoised=True,\n",
    "    denoised_fn=None,\n",
    "    cond_fn_1=cond_fn_1,\n",
    "    cond_fn_2=cond_fn_2,\n",
    "    model_kwargs={},\n",
    "    device=gpu,\n",
    "    progress=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23dfdab5f40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample[0,0,:,:].cpu().detach().numpy(), cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topodiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
