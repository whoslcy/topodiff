{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import create_models\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "\n",
    "mean_variance = create_models.mean_variance(\n",
    "    image_size=image_size,\n",
    "    num_channels=128,\n",
    "    num_res_blocks=3,\n",
    "    channel_mult=\"\",\n",
    "    learn_sigma=True,\n",
    "    use_checkpoint=False,\n",
    "    attention_resolutions=\"16,8\",\n",
    "    num_heads=4,\n",
    "    num_head_channels=-1,\n",
    "    num_heads_upsample=-1,\n",
    "    use_scale_shift_norm=True,\n",
    "    dropout=0.3,\n",
    "    resblock_updown=False,\n",
    "    use_fp16=True,\n",
    "    use_new_attention_order=False,\n",
    ")\n",
    "diffusion = create_models.gaussian_diffusion(\n",
    "    steps=1000,\n",
    "    learn_sigma=True,\n",
    "    sigma_small=False,\n",
    "    noise_schedule=\"cosine\",\n",
    "    use_kl=False,\n",
    "    predict_xstart=False,\n",
    "    rescale_timesteps=False,\n",
    "    rescale_learned_sigmas=False,\n",
    "    timestep_respacing=\"100\",\n",
    ")\n",
    "regressor = create_models.regressor(\n",
    "    image_size=image_size,\n",
    "    in_channels=1 + 3 + 2 + 2,\n",
    "    regressor_use_fp16=False,\n",
    "    regressor_width=128,\n",
    "    regressor_depth=4,\n",
    "    regressor_attention_resolutions=\"32,16,8\",\n",
    "    regressor_use_scale_shift_norm=True,\n",
    "    regressor_resblock_updown=True,\n",
    "    regressor_pool=\"spatial\",\n",
    ")\n",
    "classifier = create_models.classifier(\n",
    "    image_size=image_size,\n",
    "    in_channels=1,\n",
    "    classifier_use_fp16=False,\n",
    "    classifier_width=128,\n",
    "    classifier_depth=2,\n",
    "    classifier_attention_resolutions=\"32,16,8\",\n",
    "    classifier_use_scale_shift_norm=True,\n",
    "    classifier_resblock_updown=True,\n",
    "    classifier_pool=\"attention\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderUNetModel(\n",
       "  (time_embed): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (input_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1-2): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (x_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(256, 768, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(256, 768, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (x_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(384, 1152, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(384, 1152, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (x_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (10): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(512, 1536, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (11): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(512, 1536, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block): TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (1): AttentionBlock(\n",
       "      (norm): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "      (qkv): Conv1d(512, 1536, kernel_size=(1,), stride=(1,))\n",
       "      (attention): QKVAttentionLegacy()\n",
       "      (proj_out): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "    (1): SiLU()\n",
       "    (2): AttentionPool2d(\n",
       "      (qkv_proj): Conv1d(512, 1536, kernel_size=(1,), stride=(1,))\n",
       "      (c_proj): Conv1d(512, 2, kernel_size=(1,), stride=(1,))\n",
       "      (attention): QKVAttention()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoints_path = Path(r\".\\checkpoints\")\n",
    "cpu = torch.cpu.current_device()\n",
    "gpu = torch.cuda.current_device()\n",
    "def get_state_dict(path: Path):\n",
    "    return torch.load(path, map_location=cpu, weights_only=True)\n",
    "\n",
    "mean_variance_path = checkpoints_path / \"diff_checkpoint\" / \"model_180000.pt\"\n",
    "mean_variance.load_state_dict(get_state_dict(mean_variance_path))\n",
    "mean_variance.to(gpu)\n",
    "mean_variance.convert_to_fp16()\n",
    "mean_variance.eval()\n",
    "\n",
    "regressor_path = checkpoints_path / \"reg_checkpoint\" / \"model_350000.pt\"\n",
    "regressor.load_state_dict(get_state_dict(regressor_path))\n",
    "regressor.to(gpu)\n",
    "regressor.eval()\n",
    "\n",
    "classifier_path = checkpoints_path / \"class_checkpoint\" / \"model_299999.pt\"\n",
    "classifier.load_state_dict(get_state_dict(classifier_path))\n",
    "classifier.to(gpu)\n",
    "classifier.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "channel_count = 1\n",
    "shape = (batch_size, channel_count, image_size, image_size)\n",
    "\n",
    "def cond_fn_1(x: torch.Tensor, time_steps: torch.Tensor):\n",
    "    with torch.enable_grad():\n",
    "        x_in = x.detach().requires_grad_()\n",
    "        logits = regressor(x_in, time_steps)\n",
    "        grad = torch.autograd.grad(logits.sum(), x_in)[0]\n",
    "        return (-1) * grad[:,0,:,:].reshape(shape) * 4.0\n",
    "\n",
    "def cond_fn_2(x: torch.Tensor, time_steps: torch.Tensor):\n",
    "    with torch.enable_grad():\n",
    "        x_in = x.detach().requires_grad_()\n",
    "        logits: torch.Tensor = classifier(x_in, time_steps)\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        selected = log_probs[range(len(logits)), 1]\n",
    "        grad = torch.autograd.grad(selected.sum(), x_in)[0]\n",
    "        return grad[:,0,:,:].reshape(shape) * 3.0\n",
    "\n",
    "\n",
    "def get_boundary_condition(condition_name: str):\n",
    "    folder = Path(r\".\\data\\dataset_1_diff\\test_data_level_1\")\n",
    "    path = folder / f\"cons_{condition_name}_array_200.npy\"\n",
    "    ndarray = np.transpose(np.load(path), [2, 0, 1]).astype(np.float32)\n",
    "    tensor = torch.unsqueeze(torch.as_tensor(ndarray), 0) # Add batch size dimension\n",
    "    return tensor.to(gpu)\n",
    "\n",
    "sample = diffusion.p_sample_loop(\n",
    "    model=mean_variance,\n",
    "    shape=shape,\n",
    "    cons=get_boundary_condition(\"pf\"),\n",
    "    loads=get_boundary_condition(\"load\"),\n",
    "    BCs=get_boundary_condition(\"bc\"),\n",
    "    noise=None,\n",
    "    clip_denoised=True,\n",
    "    denoised_fn=None,\n",
    "    cond_fn_1=cond_fn_1,\n",
    "    cond_fn_2=cond_fn_2,\n",
    "    model_kwargs={},\n",
    "    device=gpu,\n",
    "    progress=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23742dd6630>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample[0,0,:,:].cpu().detach().numpy(), cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topodiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
