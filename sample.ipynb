{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import create_models\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 64\n",
    "\n",
    "mean_variance = create_models.mean_variance(\n",
    "    image_size=64,\n",
    "    num_channels=128,\n",
    "    num_res_blocks=3,\n",
    "    channel_mult=\"\",\n",
    "    learn_sigma=True,\n",
    "    use_checkpoint=False,\n",
    "    attention_resolutions=\"16,8\",\n",
    "    num_heads=4,\n",
    "    num_head_channels=-1,\n",
    "    num_heads_upsample=-1,\n",
    "    use_scale_shift_norm=True,\n",
    "    dropout=0.3,\n",
    "    resblock_updown=False,\n",
    "    use_fp16=True,\n",
    "    use_new_attention_order=False,\n",
    ")\n",
    "diffusion = create_models.gaussian_diffusion(\n",
    "    steps=1000,\n",
    "    learn_sigma=True,\n",
    "    sigma_small=False,\n",
    "    noise_schedule=\"cosine\",\n",
    "    use_kl=False,\n",
    "    predict_xstart=False,\n",
    "    rescale_timesteps=False,\n",
    "    rescale_learned_sigmas=False,\n",
    "    timestep_respacing=\"100\",\n",
    ")\n",
    "regressor = create_models.regressor(\n",
    "    image_size=image_size,\n",
    "    in_channels=1 + 3 + 2 + 2,\n",
    "    regressor_use_fp16=False,\n",
    "    regressor_width=128,\n",
    "    regressor_depth=4,\n",
    "    regressor_attention_resolutions=\"32,16,8\",\n",
    "    regressor_use_scale_shift_norm=True,\n",
    "    regressor_resblock_updown=True,\n",
    "    regressor_pool=\"spatial\",\n",
    ")\n",
    "classifier = create_models.classifier(\n",
    "    image_size=image_size,\n",
    "    in_channels=1,\n",
    "    classifier_use_fp16=False,\n",
    "    classifier_width=128,\n",
    "    classifier_depth=2,\n",
    "    classifier_attention_resolutions=\"32,16,8\",\n",
    "    classifier_use_scale_shift_norm=True,\n",
    "    classifier_resblock_updown=True,\n",
    "    classifier_pool=\"attention\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderUNetModel(\n",
       "  (time_embed): Sequential(\n",
       "    (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (input_blocks): ModuleList(\n",
       "    (0): TimestepEmbedSequential(\n",
       "      (0): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1-2): 2 x TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (3): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (x_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (4): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 128, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(256, 768, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (5): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(256, 768, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(256, 256, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (6): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (x_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (7): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 256, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(384, 1152, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (8): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(384, 1152, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(384, 384, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (9): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (x_upd): Downsample(\n",
       "          (op): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "        )\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=768, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "    )\n",
       "    (10): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 384, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(384, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(512, 1536, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "    (11): TimestepEmbedSequential(\n",
       "      (0): ResBlock(\n",
       "        (in_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (h_upd): Identity()\n",
       "        (x_upd): Identity()\n",
       "        (emb_layers): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        )\n",
       "        (out_layers): Sequential(\n",
       "          (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "          (1): SiLU()\n",
       "          (2): Dropout(p=0, inplace=False)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (skip_connection): Identity()\n",
       "      )\n",
       "      (1): AttentionBlock(\n",
       "        (norm): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (qkv): Conv1d(512, 1536, kernel_size=(1,), stride=(1,))\n",
       "        (attention): QKVAttentionLegacy()\n",
       "        (proj_out): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (middle_block): TimestepEmbedSequential(\n",
       "    (0): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "    (1): AttentionBlock(\n",
       "      (norm): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "      (qkv): Conv1d(512, 1536, kernel_size=(1,), stride=(1,))\n",
       "      (attention): QKVAttentionLegacy()\n",
       "      (proj_out): Conv1d(512, 512, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (in_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (h_upd): Identity()\n",
       "      (x_upd): Identity()\n",
       "      (emb_layers): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      )\n",
       "      (out_layers): Sequential(\n",
       "        (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "        (1): SiLU()\n",
       "        (2): Dropout(p=0, inplace=False)\n",
       "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (skip_connection): Identity()\n",
       "    )\n",
       "  )\n",
       "  (out): Sequential(\n",
       "    (0): GroupNorm32(32, 512, eps=1e-05, affine=True)\n",
       "    (1): SiLU()\n",
       "    (2): AttentionPool2d(\n",
       "      (qkv_proj): Conv1d(512, 1536, kernel_size=(1,), stride=(1,))\n",
       "      (c_proj): Conv1d(512, 2, kernel_size=(1,), stride=(1,))\n",
       "      (attention): QKVAttention()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoints_path = Path(r\".\\checkpoints\")\n",
    "cpu = torch.cpu.current_device()\n",
    "gpu = torch.cuda.current_device()\n",
    "def get_state_dict(path: Path):\n",
    "    return torch.load(path, map_location=cpu, weights_only=True)\n",
    "\n",
    "mean_variance_path = checkpoints_path / \"diff_checkpoint\" / \"model_180000.pt\"\n",
    "mean_variance.load_state_dict(get_state_dict(mean_variance_path))\n",
    "mean_variance.to(gpu)\n",
    "mean_variance.convert_to_fp16()\n",
    "mean_variance.eval()\n",
    "\n",
    "regressor_path = checkpoints_path / \"reg_checkpoint\" / \"model_350000.pt\"\n",
    "regressor.load_state_dict(get_state_dict(regressor_path))\n",
    "regressor.to(gpu)\n",
    "regressor.eval()\n",
    "\n",
    "classifier_path = checkpoints_path / \"class_checkpoint\" / \"model_299999.pt\"\n",
    "classifier.load_state_dict(get_state_dict(classifier_path))\n",
    "classifier.to(gpu)\n",
    "classifier.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "channel_count = 1\n",
    "shape = (batch_size, channel_count, image_size, image_size)\n",
    "\n",
    "def cond_fn_1(x: torch.Tensor, time_steps: torch.Tensor):\n",
    "    with torch.enable_grad():\n",
    "        x_in = x.detach().requires_grad_()\n",
    "        logits = regressor(x_in, time_steps)\n",
    "        grad = torch.autograd.grad(logits.sum(), x_in)[0]\n",
    "        return (-1) * grad[:,0,:,:].reshape(shape) * 4.0\n",
    "\n",
    "def cond_fn_2(x: torch.Tensor, time_steps: torch.Tensor):\n",
    "    with torch.enable_grad():\n",
    "        x_in = x.detach().requires_grad_()\n",
    "        logits: torch.Tensor = classifier(x_in, time_steps)\n",
    "        log_probs = F.log_softmax(logits, dim=-1)\n",
    "        selected = log_probs[range(len(logits)), 1]\n",
    "        grad = torch.autograd.grad(selected.sum(), x_in)[0]\n",
    "        return grad[:,0,:,:].reshape(shape) * 3.0\n",
    "\n",
    "\n",
    "def get_boundary_condition(condition_name: str):\n",
    "    folder = Path(r\".\\data\\dataset_1_diff\\test_data_level_1\")\n",
    "    path = folder / f\"cons_{condition_name}_array_200.npy\"\n",
    "    ndarray = np.transpose(np.load(path), [2, 0, 1]).astype(np.float32)\n",
    "    tensor = torch.unsqueeze(torch.as_tensor(ndarray), 0) # Add batch size dimension\n",
    "    return tensor.to(gpu)\n",
    "\n",
    "sample = diffusion.p_sample_loop(\n",
    "    model=mean_variance,\n",
    "    shape=shape,\n",
    "    cons=get_boundary_condition(\"pf\"),\n",
    "    loads=get_boundary_condition(\"load\"),\n",
    "    BCs=get_boundary_condition(\"bc\"),\n",
    "    noise=None,\n",
    "    clip_denoised=True,\n",
    "    denoised_fn=None,\n",
    "    cond_fn_1=cond_fn_1,\n",
    "    cond_fn_2=cond_fn_2,\n",
    "    model_kwargs={},\n",
    "    device=gpu,\n",
    "    progress=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2374b87ebd0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(sample[0,0,:,:].cpu().detach().numpy(), cmap=\"gray\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "topodiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
